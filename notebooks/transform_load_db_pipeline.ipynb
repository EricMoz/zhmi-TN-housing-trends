{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff7e178-cfad-481f-8a45-a34c16248b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Removing existing database...\n",
      "Final dataset contains 301,340 rows and 12 columns.\n",
      "Saving 301,340 rows to SQLite\n",
      "âœ… Exported cleaned data to C:\\Users\\ericm\\OneDrive\\Documents\\GitHub_Sync\\zhvi-TN-housing-trends\\data\\zhvi_tableau_ready.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "def main():\n",
    "    # === 1. Setup paths ===\n",
    "    try:\n",
    "        project_dir = Path(__file__).parent.resolve()  # Automatically gets the script's directory\n",
    "    except NameError:\n",
    "        project_dir = Path().resolve()\n",
    "    data_folder = project_dir.parent / \"zhvi_raw_files\"\n",
    "    sqlite_path = project_dir.parent / \"data\" / \"zhvi_data.db\"\n",
    "\n",
    "    if sqlite_path.exists():\n",
    "        print(\"ðŸ§¹ Removing existing database...\")\n",
    "        sqlite_path.unlink()\n",
    "    file_list = list(data_folder.glob(\"*.csv\"))  # Grabs all CSV files\n",
    "\n",
    "    if not file_list:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {data_folder}\")\n",
    "\n",
    "    # === 2. Load & process all CSV files ===\n",
    "    all_dfs = []\n",
    "\n",
    "    for file in file_list:\n",
    "        # Extract 18th character of filename that represents bedroom count corresponding to the dataset (e.g., â€˜Zip_zhvi_bdrmcnt_3_uc.csvâ€™ = 3)\n",
    "        base_name = file.name\n",
    "        bedroom_digit = base_name[17]  # Position 18\n",
    "        bedroom_count = \"5+\" if bedroom_digit == \"5\" else bedroom_digit\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"FileName\"] = base_name\n",
    "        df[\"BedroomCount\"] = bedroom_count\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    # === 3. Concatenate all data ===\n",
    "    df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # === 4. Filter to RegionType == \"zip\" to remove any duplicate headers amongst the combined files ===\n",
    "    df_all = df_all[df_all[\"RegionType\"] == \"zip\"].copy()\n",
    "\n",
    "    # === 5. Drop 'FileName' column ===\n",
    "    df_all.drop(columns=[\"FileName\"], inplace=True)\n",
    "\n",
    "    # === 6. Unpivot wide date columns into rows ===\n",
    "    id_vars = [\n",
    "        \"RegionID\", \"BedroomCount\", \"SizeRank\", \"RegionName\", \"RegionType\",\n",
    "        \"StateName\", \"State\", \"City\", \"Metro\", \"CountyName\"\n",
    "    ]\n",
    "    value_vars = [col for col in df_all.columns if col not in id_vars]\n",
    "    df_long = pd.melt(\n",
    "        df_all,\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name=\"Date\",\n",
    "        value_name=\"HomeValue\"\n",
    "    )\n",
    "\n",
    "    # === 7. Data type conversions ===\n",
    "    df_long[\"HomeValue\"] = pd.to_numeric(df_long[\"HomeValue\"], errors=\"coerce\")\n",
    "    df_long[\"Date\"] = pd.to_datetime(df_long[\"Date\"], errors=\"coerce\")\n",
    "    df_long[\"BedroomCount\"] = df_long[\"BedroomCount\"].astype(str)\n",
    "    df_long[\"RegionName\"] = df_long[\"RegionName\"].astype(str)\n",
    "\n",
    "    # === 8. Reorder columns to match original ===\n",
    "    column_order = [\n",
    "        \"RegionID\", \"BedroomCount\", \"SizeRank\", \"RegionName\", \"RegionType\",\n",
    "        \"StateName\", \"State\", \"City\", \"Metro\", \"CountyName\", \"Date\", \"HomeValue\"\n",
    "    ]\n",
    "    df_final = df_long[column_order]\n",
    "    print(f\"Final dataset contains {df_final.shape[0]:,} rows and {df_final.shape[1]} columns.\")\n",
    "\n",
    "\n",
    "    # === 9. Save to SQLite ===\n",
    "    conn = sqlite3.connect(sqlite_path)\n",
    "    df_final.to_sql(\"zhvi_data\", conn, if_exists=\"replace\", index=False)\n",
    "    print(f\"Saving {df_final.shape[0]:,} rows to SQLite\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    # === 10. Export cleaned data for Tableau ===\n",
    "    tableau_export_path = project_dir.parent / \"data\" / \"zhvi_tableau_ready.csv\"\n",
    "    df_final.to_csv(tableau_export_path, index=False)\n",
    "    print(f\"âœ… Exported cleaned data to {tableau_export_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
